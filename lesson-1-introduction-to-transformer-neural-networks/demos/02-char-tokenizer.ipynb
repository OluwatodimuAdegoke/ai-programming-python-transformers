{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z2ea-5SaF59N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Use CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9CRij9k1GDlM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DSc0ludHGE1o"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "text = Path('tiny_shakespare.txt').read_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7-9Nk7OoGGHc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: The Complete Works of William Shakespeare\n",
            "\n",
            "Author: William Shakespeare\n",
            "\n",
            "Release date: January 1, 1994 [eBook #100]\n",
            "                Most recently updated: October 29, 2024\n",
            "\n",
            "Language: English\n",
            "\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM SHAKESPEARE ***\n",
            "The Complete Works of William Shakespeare\n",
            "\n",
            "by William Shakespeare\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                    Contents\n",
            "\n",
            "    THE SONNETS\n",
            "    ALL’S WELL THAT ENDS WELL\n",
            "    THE TRAGEDY OF ANTONY AND CLEOPATRA\n",
            "    AS YOU LIKE IT\n",
            "    THE COMEDY OF ERRORS\n",
            "    THE TRAGEDY OF CORIOLANUS\n",
            "    CYMBELINE\n",
            "    THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\n",
            "    THE FIRST PART OF KING HENRY THE FOURTH\n",
            "    THE SECOND PART OF KING HENRY THE FOURTH\n",
            "    THE LIFE OF KING HENRY THE FIFTH\n",
            "    THE FIRST PART OF HENRY THE SIXTH\n",
            "    THE SECOND PART OF KING HENRY THE SIXTH\n",
            "    THE THIRD PART OF KING HENRY THE SIXTH\n",
            "    KING HENRY THE EIGHTH\n",
            "    THE LIFE AND DEATH OF KING JOHN\n",
            "    THE TRAGEDY OF JULIUS CAESAR\n",
            "    THE TRAGEDY OF KING LEAR\n",
            "    LOVE’S LABOUR’S\n"
          ]
        }
      ],
      "source": [
        "print(text[0:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qg-yHMXPGHYq"
      },
      "outputs": [],
      "source": [
        "class CharTokenizer:\n",
        "  def __init__(self, vocabulary):\n",
        "    self.token_id_for_char = {char: token_id for token_id, char in enumerate(vocabulary)}\n",
        "    self.char_for_token_id = {token_id: char for token_id, char in enumerate(vocabulary)}\n",
        "\n",
        "  @staticmethod\n",
        "  def train_from_text(text):\n",
        "    vocabulary = set(text)\n",
        "    return CharTokenizer(sorted(list(vocabulary)))\n",
        "\n",
        "  def encode(self, text):\n",
        "    token_ids = []\n",
        "    for char in text:\n",
        "      token_ids.append(self.token_id_for_char[char])\n",
        "    return torch.tensor(token_ids, dtype=torch.long)\n",
        "\n",
        "  def decode(self, token_ids):\n",
        "    chars = []\n",
        "    for token_id in token_ids.tolist():\n",
        "      chars.append(self.char_for_token_id[token_id])\n",
        "    return ''.join(chars)\n",
        "\n",
        "  def vocabulary_size(self):\n",
        "    return len(self.token_id_for_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pAYBFds4GNAb"
      },
      "outputs": [],
      "source": [
        "tokenizer = CharTokenizer.train_from_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LKq-R9xvJ3RX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([36, 62, 69, 69, 72,  2, 80, 72, 75, 69, 61])\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(\"Hello world\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tWpR_hr9GOKs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello world\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokenizer.encode(\"Hello world\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3a7qPM-mGPur"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocabulary_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UbtX7_JtHFXL"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(depth=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2I3m9KI6HM-S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '\\t',\n",
            " 1: '\\n',\n",
            " 2: ' ',\n",
            " 3: '!',\n",
            " 4: '#',\n",
            " 5: '$',\n",
            " 6: '%',\n",
            " 7: '&',\n",
            " 8: \"'\",\n",
            " 9: '(',\n",
            " 10: ')',\n",
            " 11: '*',\n",
            " 12: ',',\n",
            " 13: '-',\n",
            " 14: '.',\n",
            " 15: '/',\n",
            " 16: '0',\n",
            " 17: '1',\n",
            " 18: '2',\n",
            " 19: '3',\n",
            " 20: '4',\n",
            " 21: '5',\n",
            " 22: '6',\n",
            " 23: '7',\n",
            " 24: '8',\n",
            " 25: '9',\n",
            " 26: ':',\n",
            " 27: ';',\n",
            " 28: '?',\n",
            " 29: 'A',\n",
            " 30: 'B',\n",
            " 31: 'C',\n",
            " 32: 'D',\n",
            " 33: 'E',\n",
            " 34: 'F',\n",
            " 35: 'G',\n",
            " 36: 'H',\n",
            " 37: 'I',\n",
            " 38: 'J',\n",
            " 39: 'K',\n",
            " 40: 'L',\n",
            " 41: 'M',\n",
            " 42: 'N',\n",
            " 43: 'O',\n",
            " 44: 'P',\n",
            " 45: 'Q',\n",
            " 46: 'R',\n",
            " 47: 'S',\n",
            " 48: 'T',\n",
            " 49: 'U',\n",
            " 50: 'V',\n",
            " 51: 'W',\n",
            " 52: 'X',\n",
            " 53: 'Y',\n",
            " 54: 'Z',\n",
            " 55: '[',\n",
            " 56: ']',\n",
            " 57: '_',\n",
            " 58: 'a',\n",
            " 59: 'b',\n",
            " 60: 'c',\n",
            " 61: 'd',\n",
            " 62: 'e',\n",
            " 63: 'f',\n",
            " 64: 'g',\n",
            " 65: 'h',\n",
            " 66: 'i',\n",
            " 67: 'j',\n",
            " 68: 'k',\n",
            " 69: 'l',\n",
            " 70: 'm',\n",
            " 71: 'n',\n",
            " 72: 'o',\n",
            " 73: 'p',\n",
            " 74: 'q',\n",
            " 75: 'r',\n",
            " 76: 's',\n",
            " 77: 't',\n",
            " 78: 'u',\n",
            " 79: 'v',\n",
            " 80: 'w',\n",
            " 81: 'x',\n",
            " 82: 'y',\n",
            " 83: 'z',\n",
            " 84: 'À',\n",
            " 85: 'Æ',\n",
            " 86: 'Ç',\n",
            " 87: 'É',\n",
            " 88: 'à',\n",
            " 89: 'â',\n",
            " 90: 'æ',\n",
            " 91: 'ç',\n",
            " 92: 'è',\n",
            " 93: 'é',\n",
            " 94: 'ê',\n",
            " 95: 'ë',\n",
            " 96: 'î',\n",
            " 97: 'œ',\n",
            " 98: '—',\n",
            " 99: '‘',\n",
            " 100: '’',\n",
            " 101: '“',\n",
            " 102: '”',\n",
            " 103: '•',\n",
            " 104: '…',\n",
            " 105: '™'}\n"
          ]
        }
      ],
      "source": [
        "pp.pprint(tokenizer.char_for_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "olX9rHjxHQih"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\t': 0,\n",
            " '\\n': 1,\n",
            " ' ': 2,\n",
            " '!': 3,\n",
            " '#': 4,\n",
            " '$': 5,\n",
            " '%': 6,\n",
            " '&': 7,\n",
            " \"'\": 8,\n",
            " '(': 9,\n",
            " ')': 10,\n",
            " '*': 11,\n",
            " ',': 12,\n",
            " '-': 13,\n",
            " '.': 14,\n",
            " '/': 15,\n",
            " '0': 16,\n",
            " '1': 17,\n",
            " '2': 18,\n",
            " '3': 19,\n",
            " '4': 20,\n",
            " '5': 21,\n",
            " '6': 22,\n",
            " '7': 23,\n",
            " '8': 24,\n",
            " '9': 25,\n",
            " ':': 26,\n",
            " ';': 27,\n",
            " '?': 28,\n",
            " 'A': 29,\n",
            " 'B': 30,\n",
            " 'C': 31,\n",
            " 'D': 32,\n",
            " 'E': 33,\n",
            " 'F': 34,\n",
            " 'G': 35,\n",
            " 'H': 36,\n",
            " 'I': 37,\n",
            " 'J': 38,\n",
            " 'K': 39,\n",
            " 'L': 40,\n",
            " 'M': 41,\n",
            " 'N': 42,\n",
            " 'O': 43,\n",
            " 'P': 44,\n",
            " 'Q': 45,\n",
            " 'R': 46,\n",
            " 'S': 47,\n",
            " 'T': 48,\n",
            " 'U': 49,\n",
            " 'V': 50,\n",
            " 'W': 51,\n",
            " 'X': 52,\n",
            " 'Y': 53,\n",
            " 'Z': 54,\n",
            " '[': 55,\n",
            " ']': 56,\n",
            " '_': 57,\n",
            " 'a': 58,\n",
            " 'b': 59,\n",
            " 'c': 60,\n",
            " 'd': 61,\n",
            " 'e': 62,\n",
            " 'f': 63,\n",
            " 'g': 64,\n",
            " 'h': 65,\n",
            " 'i': 66,\n",
            " 'j': 67,\n",
            " 'k': 68,\n",
            " 'l': 69,\n",
            " 'm': 70,\n",
            " 'n': 71,\n",
            " 'o': 72,\n",
            " 'p': 73,\n",
            " 'q': 74,\n",
            " 'r': 75,\n",
            " 's': 76,\n",
            " 't': 77,\n",
            " 'u': 78,\n",
            " 'v': 79,\n",
            " 'w': 80,\n",
            " 'x': 81,\n",
            " 'y': 82,\n",
            " 'z': 83,\n",
            " 'À': 84,\n",
            " 'Æ': 85,\n",
            " 'Ç': 86,\n",
            " 'É': 87,\n",
            " 'à': 88,\n",
            " 'â': 89,\n",
            " 'æ': 90,\n",
            " 'ç': 91,\n",
            " 'è': 92,\n",
            " 'é': 93,\n",
            " 'ê': 94,\n",
            " 'ë': 95,\n",
            " 'î': 96,\n",
            " 'œ': 97,\n",
            " '—': 98,\n",
            " '‘': 99,\n",
            " '’': 100,\n",
            " '“': 101,\n",
            " '”': 102,\n",
            " '•': 103,\n",
            " '…': 104,\n",
            " '™': 105}\n"
          ]
        }
      ],
      "source": [
        "pp.pprint(tokenizer.token_id_for_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLnPsybaHTew"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
